---
layout: post
title: Vision Transformer with Deformable Attention
categories: ['Paper Summary', 'Vision Transformer']
---

**Title**: Vision Transformer with Deformable Attention ([Link](https://arxiv.org/pdf/2201.00520v1.pdf)) \
**Affiliation**: Zhuofan Xia et al., Tsinghua University / AWS AI / Beijing Academy of AI

<center><img src="https://gcdn.pbrd.co/images/fLv9hjYXnVHv.png?o=1" width="350"/></center>

![Overview](https://gcdn.pbrd.co/images/6BNBda5adoTN.png?o=1)
![Architecture](https://gcdn.pbrd.co/images/y03CXt6TwaCL.png?o=1)


#### Summary

In vision transformers, the excessive number of key-query interactions yields high computation cost, high memory usage, convergence time, and features may (potentially) be affected by irrelevant parts which are beyond region of interest. 
This paper proposes a novel deformable self-attention module, where the positions of keys and values are selected in a data-dependent way. This allows the attention mechanism to model long-range interactions while focusing on more relevant regions as well. Overall, the proposed DAT (Deformable Attention Transformers) achieves a new state of the art on image classification and dense prediction (detection, segmentation) tasks.

**Related work**: Swin-Transformer, PVT, DCN, DETR 
* SwinT and PVT propose data-agnostic sparsity (locality), limited capabilities.
* DCN is for convolution, different key for each query --> high cost for transformers 
* DETR proposes to use just around 4 keys per query, which the paper suggests is "unfit" for feature extraction as lack of keys result in limited representation power.

#### Key Components

1. Deformable Attention module

A uniform grid of points (less than the number of original patches/pixels) are generated as references (key/value positions). Then the query is input to the offset generation network to output offsets for each reference point, which is shared for all query positions. The offsets are scaled by a **predefined** factor to prevent too large offset. 

The features and relative positional embedding are then sampled at reference + offset positions by bilinear interpolation.

2. Offset generation, Offset groups

Offset generation: 2 convolutional modules. First is depthwise convolution to capture local features (with stride&kernel size of s, where s is the size of grid). 
After GeLU, the second convolutional module is a 1x1 convolution to output 2 values (offset in x and y directions).

Offset groups: To promote diversity of deformed points, split feature channel to G groups (where G << M, M being the number of heads). Each group has different offset outputs. Since G << M, multiple attention heads use the same offset outputs (same group of deformed keys and values).

3. Deformable relative position embedding

Considering a relative position bias table of (2H-1) x (2W-1), compute relative displacements, then interpolate by the continuous relative displcement values.

#### Personal reviews
* While the tables could have shown a more distinct comparison if compared against ViTs (in terms of performance and efficiency), the paper compares against newer methods such as DPT, Swin, and GLiT. The proposed method still outperforms will acceptable increases in computation/parameters.
* The considerations made in this paper shows that a lot of thought has gone into facilitating deformable attention in vision transformers (offset generator, grid reference points, offset groups...). This paper would be a great reference for future work. 
* However, the choice of the 'predefined' scaling parameter to prevent large offset values seem heuristic, considering that the offset values would be one of the most influential factor of the performance. 
* Also, while figure 4 shows that the deformed points focus "more" on the important parts of the images, many reference points still look at background portions of the images. I'm not certain as to whehter this visualization is very effective.
* The paper uses swin transformers in the earlier layers 'to have better representation in the earlier stages', but this seems to go against the initial motivation of 'global attention usually results in the almost same attention patterns for different queries', which also happens in the earlier layers of networks as well. While using Swin in the earlier layers does show better results empirically, I believe this part deserves more analysis.
