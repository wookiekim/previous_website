---
layout: post
title: EEC-Learning to Encode and Regenerate Images for Continual Learning
categories: ['Paper Summary', 'Continual Learning']
---

**Title**: EEC: Learning to Encode and Regenerate Images for Continual Learning ([Link](https://openreview.net/forum?id=lWaz5a9lcFU)) \
**Affiliation**: Ali Ayub et al., Pennsylvannia State University

![Overview](https://gcdn.pbrd.co/images/0kze81wordxs.png?o=1)

#### Summary

The two main challenges in continual learning are catastrophic forgetting and memory limitations on the storage of data. To tackle these challenges, this paper proposes to train **autoencoders** with style transfer to encode and store images, which can be reconstructed for further training. Since the reconstructed images may be degraded, the loss terms are reweighted accordingly. In case the encoded images also pose memory problems, the paper also proposes to convert the encoded images (episodes) to centroids and covariance matrices through the means of clustering to save disk space. This approach improves classification accuracy 13-17% over SoTA methods which use generative methods, while requiring 78% less storage space.

Preliminarily submitted to ICML 2020 workshop.

**vs. Related work**: 
* storing features output from pretrained networks - unfair
* storing original images (partial) - cannot prevent catastrophic forgetting, or cause memory overload if too many
* using GANs instead of autoencoders - may create images which does not belong to any learned class
    * using cGANs - create class specific images, but **empirically** shown to be worse than just using autoencoders
* Most approaches work well on MNIST, but not as so on complex datasets like ImageNet
* Autoencoders alone output blurry images, which has room for improvement (in encoding stages, to improve encoded information)

#### Key Components

###### Autoencoder Training with Neural Style Transfer

On top of conventional autoencoder training (using reconstruction loss), add the content loss (from neural style transfer) which aims to maintain the content of the original image. This is to alleviate the blurriness of images reconstructed using autoencoders. The content loss aims to minimize the difference between **features extracted from a feature extractor**, where the frozen version of the final classifier is used as the feature extractor for the training of these autoencoders. This qualitatively improves the reconstructed images of the autoencoders.

###### Memory Integration
Even with the encoded episodes, the system can run out of memory. In those cases, the learned episodes can be summarized in the form of centroids and covariance matrices as a result of clustering, removing the original episodes afterwards.

###### Rehearsal, Pseudorehearsal and Classifier Training
**Rehearsal**: Reconstruct images from episodes using autoencoders' decoder, then train.
**Classifier Training**: Use new images and class labels for training.

**Pseudorehearsal**: Sample a multivariate Gaussian distribution with mean as the centroid and the covariance matrix to generate a large set of pseudo-encoded episodes. The episodes are then passed through the autoencoderâ€™s decoder to generate pseudo-images for the previous classes.

However, considering that pseudo-images could be noisy, we pass these images through the final classifier, and use only those images which have the same predicted results as their actual original class labels. 

**Sample Decay Weight**: pseudo-images can still be quite different from the original images, hurting the performance. Therefore, the loss terms are weighed based on the ratio of **the classification accuracy of the reconstructed images**: **accuracy of the original images** on the final classifier network trained on previous tasks.

#### Personal reviews
* **NOTE**: This paper has the lowest pre-rebuttal scores among the accepted papers of ICLR 2021.
* From the perspective of a person new to this task, the paper is rather self-contained and easy to follow/understand, without having to refer to many other papers for reference.
* The ablation studies are sufficient to show the significance of each proposed components
* The reviews of the original ICLR submissions were very well addressed throughout the paper (ex comparison vs other generation methods, using larger image resolution...). While the paper is not seamless and it does raise many questions (maybe because I'm not experienced in this field), I agree with the decision that this paper deserves an accept.
* Minor typos here and there, ex) 4.2 Implementaion details (misspelling)
* Many quantitative results are simply presented as part of text (not in tables) and sometimes without comparison to other baseline/SoTA methods. The presentation could be better, and the lack of comparison downgrades the persuasiveness of the results.
