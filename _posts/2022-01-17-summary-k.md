---
layout: post
title: Bootstrap Your Own Correspondences
categories: ['Paper Summary', 'Point Cloud Registration', 'Correspondence Estimation', 'Self-supervised Learning']
permalink: /summary_byoc/
---

**Title**: Bootstrap Your Own Correspondences ([Link](https://arxiv.org/pdf/2106.00677.pdf)) \
**Affiliation**: Mohamed El Banani et al., University of Michigan - ICCV 2021

![Overview](https://gcdn.pbrd.co/images/AmaFMLGjocp2.png?o=1)

#### Summary
This paper propose BYOC, a self-supervised pipeline for correspondence estimation and point cloud registration. The key insight of this paper is that randomly initialized CNNs are actually quite good at establishing correspondences, which they use as the initial self-supervision signal to train the network, gradually bootstrapping the learning of both visual and geometric (3D encoder) features. The proposed method outperforms traditional/learned descriptors, while performing on par with existing SoTA methods.

#### Key Components

* Geometric feature extraction using FCGF / other 3D encoder networks, usually voxelized in this paper.
* Visual feature extraction from randomly-initialized ResNet encoder with just two residual blocks (much smaller)
* Correspondence estimation, with each correspondence given weight according to Lowe's ratio test
  * 1 - (top-1 distance)/(top-2 distance)
  * This could actually be quite an effective way of weighting the correspondences!
* 3D encoders are not as good at identifying correspondences compared to the ResNet backbone
  * aided from the highly-weighted correspondences from the visual features (CNN-based)
  * Uses the SimSiam setup instead of the typical contrastive setup
    * Given a correspondence, first project the features using a two-layer MLP projection head and apply a stop-gradient operator on the features
  * Loss if based on the cosine distance between each geometric feature and the projection of its correspondence

#### Dataset
ScanNet, 3DMatch

#### Personal reviews
* While each proposed module may not be novel, it is a combination of existing novelties (SimSiam, Lowe's ratio test) which is derived from a novel insight (randomly initialized ResNets are not that bad at capturing correspondences) to solve a novel problem (self-supervised correspondence estimation).
* While the paper was overall easy to read and follow, I couldn't fully understand why they do not use the visual feature branch at test time. Maybe empirically,it showed no improvement and the additional memory usage was meaningless? (Since they used the visual feature branch at train time already.)