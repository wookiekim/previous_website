---
layout: post
title: Learning Multiview 3D point cloud registration
categories: ['Paper Summary', 'Point Cloud Registration', 'Transformation Synchronization']
permalink: /summary_multiview3dregistration/
---

**Title**: Learning Multiview 3D point cloud registration ([Link](https://openaccess.thecvf.com/content_CVPR_2020/papers/Gojcic_Learning_Multiview_3D_Point_Cloud_Registration_CVPR_2020_paper.pdf)) \
**Affiliation**: Zan Gojcic, Caifa Zhou et al., ETH Zurich - CVPR 2020

![Overview](https://gcdn.pbrd.co/images/LRDXAJn3v7T1.png?o=1)

#### Summary
Existing methods for multi-view point cloud registration usually extends pairwise registration step by step to eventually align all the point clouds to a single reference frame, which would take a long time and also be suboptimal. This paper proposes to solve multi-view 3D point cloud registration in a single end-to-end trainable pipeline, outperforming SoTA methods (at that point of time) while being computationally less costly.

#### Key Components

##### Differentiable Transformation Synchronization
* Divide the problem to Rotation synchronization and Translation Synchronization
* Each synchronization aims to retrieve global rotation matrix / global translation vector by solving a certain minimization problem based on their observed ratios
* The above synchronization scheme facilitates an iterative approach, to update the rotation matrices and the confidence weights accordingly.

##### Miscellaneous
* Supervised using FCGF loss (from what I remember, the **hardest-contrastive loss**)
* Pairwise registration is done first (between all pairs) for an initialization
* With a graph representation (node: each fragment, edge: estimated relative transformation and confidence weight), the edges are iteratively updated
* The confidence is an aggregation of local confidence (using MLP and ratio of inliers) and global confidence (using relative transformation parameters)
* Loss is an addition of registration loss / classification loss / synchronization loss (and a "conf" loss which is not specified well in the paper...) 

#### Dataset
ScanNet, 3DMatch

#### Personal reviews
* The proposed method indeed is end-to-end trainable, faster than existing multiview registration pipelines, and achieve better performances. Also, the proposed transformation synchronization algorithm is a novel component which enables this.
* However, the presentation of the paper could be improved IMHO. Some losses are not well elaborated, and notations and explanations could be better placed so that the readers won't have to look back and forth to have a clear understanding of the paper. This is especially severe before section 4, where some unexplained notations appear in the formulations.
* The current formulation of transformation synchronization does seem to have a lot of room for improvement, and there are some underexplained heuristics. For example, why was the Cauchy weighting function used? Why were the two confidences (local and global) combined using harmonic loss?