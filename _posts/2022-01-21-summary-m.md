---
layout: post
title: Curriculum learning
categories: ['Paper Summary', 'Curriculum Learning']
permalink: /summary_curriculumlearning/
---

**Title**: Curriculum Learning ([Link](https://dl.acm.org/doi/10.1145/1553374.1553380)) \
**Affiliation**: Yoshua Bengio et al., ETH Zurich - ICML 2009

![Overview](https://gcdn.pbrd.co/images/ikhh7kIF3TII.png?o=1)

#### Summary
This is the first paper to propose the idea of curriculum learning. While the actual formulation is (quite) more complex than I thought, the most important idea is that if a network learns from easier examples first then from harder examples, it finally ends up generalizing better compared to looking at both easy & hard examples at the same time. The main limitation (and future work) stated here is that "it is hard to determine which examples are just adequately easy/hard at a certain moment in training time", and I believe this has motivated a lot of future work (instance weighting during training or so...).
In this summary, I mainly focus on the shape classification scenario as I am a computer vision person at the time of writing.

#### Key Components

##### Shape recognition
* Classify geometric shapes into 3 classes: rectangle, ellipse, triangle.
* Easy examples for initial curriculum learning: squares, circles, equilateral triangles.
* The network is trained on easier examples until "switch epoch", then trained till epoch 256. (Refer to figure)
* The figure is rather self-explanatory (surprising results, too..!)
* To eliminate the explanation that better results are obtained with the curriculum because of seeing more examples
  * a no-curriculum model is trained with the union of easy/original dataset.
  * the final test error is still significantly worse than using curriculum (~= switch epoch @ 16)

#### Personal reviews
* While the paper is quite old (2009), the insights are still very interesting, and seems to be very well-organized and prepared considering the situation at that time.
* Many other types of learning have been mentioned in the paper as well (multi-task learning, transfer learning, active learning, lifelong learning), and there is a trend of using semi- or un- supervised learning to rely less on data. A combination of those two for tackling my research criteria would be inspiring.